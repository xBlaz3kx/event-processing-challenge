version: "3.9"
services:

  # Traefik is a reverse proxy and load balancer that makes deploying microservices easy.
  # Used for local development and testing.
  traefik:
    image: "traefik:v3.0"
    container_name: "traefik"
    restart: always
    command:
      - "--ping=true"
      - "--api.insecure=true"
      - "--api.dashboard=true"
      - "--providers.docker=true"
      - "--entrypoints.http.address=:80"
      - "--entrypoints.https.address=:443"
      - "--entrypoints.metrics.address=:9090"
      - "--accesslog=true"
      - "--accesslog.format=json"
      - "--log.level=debug"
      - "--log.format=json"
      - "--core.defaultRuleSyntax=v2"
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.entryPoint=metrics"
      - "--tracing.otlp.grpc.endpoint=lgtm-stack:4317"
      - "--tracing.otlp.grpc=true"
      - "--tracing.otlp.grpc.insecure=true"
      - "--metrics.otlp=true"
      - "--metrics.otlp.grpc.endpoint=lgtm-stack:4317"
      - "--metrics.otlp.grpc.insecure=true"
      - "--metrics.otlp.addRoutersLabels=true"
      - "--metrics.otlp.addServicesLabels=true"
    ports:
      - "80:80"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    healthcheck:
      test: wget --spider --tries=1 http://localhost:8080/ping || exit 1
      interval: 10s
      timeout: 5s
      retries: 3

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # Using Kafka as a streaming platform for real-time event processing.
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10

  # Benthos is a stream processor, used for Kafka message enrichment.
  benthos:
    image: jeffail/benthos:latest
    hostname: benthos
    restart: on-failure
    command: "-w --chilled -c ./config.yaml -r ./resources.yaml streams ./streams/*.yaml"
    profiles:
      - emanual
    volumes:
      - ../configs/benthos/config.yaml:/config.yaml
      - ../configs/benthos/resources.yaml:/resources.yaml
      - ../configs/benthos/streams:/streams
    depends_on:
      - kafka
    healthcheck:
      test: curl -f http://localhost:4195/ready || exit 1
      start_period: 15s
      interval: 15s
      timeout: 5s
      retries: 3

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    hostname: schema-registry
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092

  ksqldb-server:
    image: confluentinc/ksqldb-server:latest
    hostname: ksqldb-server
    depends_on:
      - kafka
      - schema-registry
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      # Configuration to embed Kafka Connect support.
      KSQL_CONNECT_GROUP_ID: "ksql-connect-cluster"
      KSQL_CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      KSQL_CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      KSQL_CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      KSQL_CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_CONNECT_CONFIG_STORAGE_TOPIC: "_ksql-connect-configs"
      KSQL_CONNECT_OFFSET_STORAGE_TOPIC: "_ksql-connect-offsets"
      KSQL_CONNECT_STATUS_STORAGE_TOPIC: "_ksql-connect-statuses"
      KSQL_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_PLUGIN_PATH: "/usr/share/kafka/plugins"

  # We'll use the cli as the migration tool for the ksqlDB.
  ksqldb-cli:
    image: confluentinc/ksqldb-cli:latest
    depends_on:
      - ksqldb-server
    command:
      - ksql-migrations new-project /share/ksql-migrations http://ksqldb-server:8088
      - ksql-migrations apply -a
    volumes:
      - ../../scripts/ksql:/share/ksql-migrations

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.3.2
    hostname: kafka-connect
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://chema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/etc/kafka-connect/jars,/usr/share/confluent-hub-components'
    volumes:
      - ./connectors:/etc/kafka-connect/jars/
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    command:
      - bash
      - -c
      - |
        confluent-hub install --no-prompt debezium/debezium-connector-mysql:latest
        confluent-hub install --no-prompt confluentinc/kafka-connect-datagen:0.4.0
        /etc/confluent/docker/run

  kafka-rest-proxy:
    image: confluentinc/cp-kafka-rest:7.3.2
    hostname: kafka-rest-proxy
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_REST_LISTENERS: http://0.0.0.0:8082/
      KAFKA_REST_SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081/
      KAFKA_REST_HOST_NAME: kafka-rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:19092
    depends_on:
      - zookeeper
      - kafka
      - schema-registry

  # Conduktor for UI
  conduktor:
    image: conduktor/conduktor-console:1.21.0
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.conduktor.loadbalancer.server.port=8080
      - traefik.http.routers.conduktor.rule=Host(`conduktor.localhost`)
      - traefik.http.routers.conduktor.service=conduktor
      - traefik.http.routers.conduktor.entrypoints=http
    volumes:
      - conduktor_data:/var/conduktor
    environment:
      CDK_DATABASE_URL: "postgresql://conduktor:conduktor@postgresql:5432/conduktor-console"
      CDK_CLUSTERS_0_ID: "default"
      CDK_CLUSTERS_0_NAME: "My Local Kafka Cluster"
      CDK_CLUSTERS_0_COLOR: "#0013E7"
      CDK_CLUSTERS_0_BOOTSTRAPSERVERS: "PLAINTEXT://kafka:9092"
      CDK_CLUSTERS_0_SCHEMAREGISTRY_URL: "http://schema-registry:8081"
      CDK_CLUSTERS_0_KAFKACONNECTS_0_URL: "http://kafka-connect:8083"
      CDK_CLUSTERS_0_KAFKACONNECTS_0_NAME: "kafka connect"

  postgresql:
    image: postgres:14
    hostname: postgresql
    volumes:
      - pg_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: "conduktor-console"
      POSTGRES_USER: "conduktor"
      POSTGRES_PASSWORD: "conduktor"
      POSTGRES_HOST_AUTH_METHOD: "scram-sha-256"

  # Using redis as a caching mechanism for the application. Using redis stack because of the UI.
  redis:
    image: redis/redis-stack:latest
    hostname: redis
    container_name: redis
    restart: on-failure
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.redis.loadbalancer.server.port=8001
      - traefik.http.routers.redis.rule=Host(`redis.localhost`)
      - traefik.http.routers.redis.service=redis
      - traefik.http.routers.redis.entrypoints=http
    volumes:
      - redis:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 3

  player-service:
    image: xblaz3kx/player-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_player
    command: -c /config/config.yaml
    depends_on:
      - kafka
      - database
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.player-service.loadbalancer.server.port=8080
      - traefik.http.routers.player-service.rule=Host(`api.localhost`) && PathPrefix(`/player`)
      - traefik.http.routers.player-service.service=player-service
      - traefik.http.routers.player-service.entrypoints=http
    volumes:
      - ../configs/player.service.yaml:/config/config.yaml

  currency-service:
    image: xblaz3kx/currency-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_currency
    command: -c /config/config.yaml
    depends_on:
      - kafka
      - redis
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.currency-service.loadbalancer.server.port=8080
      - traefik.http.routers.currency-service.rule=Host(`api.localhost`) && PathPrefix(`/currency`)
      - traefik.http.routers.currency-service.service=currency-service
      - traefik.http.routers.currency-service.entrypoints=http
    volumes:
      - ../configs/currency.service.yaml:/config/config.yaml

  description-service:
    image: xblaz3kx/description-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_description
    command: -c /config/config.yaml
    depends_on:
      - kafka
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.description-service.loadbalancer.server.port=8080
      - traefik.http.routers.description-service.rule=Host(`api.localhost`) && PathPrefix(`/events/description`)
      - traefik.http.routers.description-service.service=description-service
      - traefik.http.routers.description-service.entrypoints=http
    volumes:
      - ../configs/description.service.yaml:/config/config.yaml

  log-service:
    image: xblaz3kx/log-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_log
    command: -c /config/config.yaml
    depends_on:
      - kafka
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.log-service.loadbalancer.server.port=8080
      - traefik.http.routers.log-service.rule=Host(`api.localhost`) && PathPrefix(`/materialize`)
      - traefik.http.routers.log-service.service=description-service
      - traefik.http.routers.log-service.entrypoints=http
    volumes:
      - ../configs/log.service.yaml:/config/config.yaml

  # Generating the events
  generator:
    image: xblaz3kx/generator:latest
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_generator
    environment:
      - KAFKA_BROKERS=kafka:9092
    profiles:
      - manual

  # Database for the application
  database:
    image: postgres:14-alpine
    hostname: postgres
    environment:
      - POSTGRES_USER=casino
      - POSTGRES_PASSWORD=casino
    volumes:
      - "../../scripts/db/migrations:/docker-entrypoint-initdb.d"
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  redis:
  postgres:
  conduktor_data:
  pg_data: