version: "3.8"

services:

  # Traefik is a reverse proxy and load balancer that makes deploying microservices easy.
  # Used for local development and testing.
  traefik:
    image: "traefik:v3.0"
    container_name: "traefik"
    restart: always
    command:
      - "--ping=true"
      - "--api.insecure=true"
      - "--api.dashboard=true"
      - "--providers.docker=true"
      - "--entrypoints.http.address=:80"
      - "--entrypoints.https.address=:443"
      - "--entrypoints.metrics.address=:9090"
      - "--accesslog=true"
      - "--accesslog.format=json"
      - "--log.level=debug"
      - "--log.format=json"
      - "--core.defaultRuleSyntax=v2"
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.entryPoint=metrics"
      - "--tracing.otlp.grpc.endpoint=lgtm-stack:4317"
      - "--tracing.otlp.grpc=true"
      - "--tracing.otlp.grpc.insecure=true"
      - "--metrics.otlp=true"
      - "--metrics.otlp.grpc.endpoint=lgtm-stack:4317"
      - "--metrics.otlp.grpc.insecure=true"
      - "--metrics.otlp.addRoutersLabels=true"
      - "--metrics.otlp.addServicesLabels=true"
    ports:
      - "80:80"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    healthcheck:
      test: wget --spider --tries=1 http://localhost:8080/ping || exit 1
      interval: 10s
      timeout: 5s
      retries: 3

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # Using Kafka as a streaming platform for real-time event processing.
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10

  # Benthos is a stream processor, used for Kafka message enrichment.
  benthos:
    image: jeffail/benthos:latest
    hostname: benthos
    restart: on-failure
    command: "-w --chilled -c ./config.yaml -r ./resources.yaml streams ./streams/*.yaml"
    profiles:
      - emanual
    volumes:
      - ../configs/benthos/config.yaml:/config.yaml
      - ../configs/benthos/resources.yaml:/resources.yaml
      - ../configs/benthos/streams:/streams
    depends_on:
      - kafka
    healthcheck:
      test: curl -f http://localhost:4195/ready || exit 1
      start_period: 15s
      interval: 15s
      timeout: 5s
      retries: 3

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092

  ksqldb-server:
    image: confluentinc/ksqldb-server:latest
    hostname: ksqldb-server
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8088:8088"
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka:9092
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      # Configuration to embed Kafka Connect support.
      KSQL_CONNECT_GROUP_ID: "ksql-connect-cluster"
      KSQL_CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
      KSQL_CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      KSQL_CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      KSQL_CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_CONNECT_CONFIG_STORAGE_TOPIC: "_ksql-connect-configs"
      KSQL_CONNECT_OFFSET_STORAGE_TOPIC: "_ksql-connect-offsets"
      KSQL_CONNECT_STATUS_STORAGE_TOPIC: "_ksql-connect-statuses"
      KSQL_CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      KSQL_CONNECT_PLUGIN_PATH: "/usr/share/kafka/plugins"

    # Access the cli by running:
    # > docker-compose exec ksqldb-cli  ksql http://primary-ksqldb-server:8088
  ksqldb-cli:
    image: confluentinc/ksqldb-cli:latest
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server
    entrypoint: /bin/sh
    tty: true

  # Using redis as a caching mechanism for the application. Using redis stack because of the UI.
  redis:
    image: redis/redis-stack:latest
    hostname: redis
    container_name: redis
    restart: on-failure
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.redis.loadbalancer.server.port=8001
      - traefik.http.routers.redis.rule=Host(`redis.localhost`)
      - traefik.http.routers.redis.service=redis
      - traefik.http.routers.redis.entrypoints=http
    volumes:
      - redis:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      start_period: 10s
      interval: 10s
      timeout: 5s
      retries: 3

  player-service:
    image: xblaz3kx/player-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_player
    command: -c /config/config.yaml
    depends_on:
      - kafka
      - database
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.player-service.loadbalancer.server.port=8080
      - traefik.http.routers.player-service.rule=Host(`api.localhost`) && PathPrefix(`/player`)
      - traefik.http.routers.player-service.service=player-service
      - traefik.http.routers.player-service.entrypoints=http
    volumes:
      - ../configs/player.service.yaml:/config/config.yaml

  currency-service:
    image: xblaz3kx/currency-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_currency
    command: -c /config/config.yaml
    depends_on:
      - kafka
      - redis
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.currency-service.loadbalancer.server.port=8080
      - traefik.http.routers.currency-service.rule=Host(`api.localhost`) && PathPrefix(`/currency`)
      - traefik.http.routers.currency-service.service=currency-service
      - traefik.http.routers.currency-service.entrypoints=http
    volumes:
      - ../configs/currency.service.yaml:/config/config.yaml

  description-service:
    image: xblaz3kx/description-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_description
    command: -c /config/config.yaml
    depends_on:
      - kafka
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.description-service.loadbalancer.server.port=8080
      - traefik.http.routers.description-service.rule=Host(`api.localhost`) && PathPrefix(`/events/description`)
      - traefik.http.routers.description-service.service=description-service
      - traefik.http.routers.description-service.entrypoints=http
    volumes:
      - ../configs/description.service.yaml:/config/config.yaml

  log-service:
    image: xblaz3kx/log-service
    restart: on-failure
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_log
    command: -c /config/config.yaml
    depends_on:
      - kafka
    labels:
      - traefik.enable=true
      - traefik.tags=public
      - traefik.http.services.log-service.loadbalancer.server.port=8080
      - traefik.http.routers.log-service.rule=Host(`api.localhost`) && PathPrefix(`/materialize`)
      - traefik.http.routers.log-service.service=description-service
      - traefik.http.routers.log-service.entrypoints=http
    volumes:
      - ../configs/log.service.yaml:/config/config.yaml

  # Generating the events
  generator:
    image: xblaz3kx/generator:latest
    build:
      context: ../..
      dockerfile: ./build/Dockerfile_generator
    environment:
      - KAFKA_BROKERS=kafka:9092
    profiles:
      - manual

  # Database for the application
  database:
    image: postgres:14-alpine
    hostname: postgres
    environment:
      - POSTGRES_USER=casino
      - POSTGRES_PASSWORD=casino
    volumes:
      - "../../scripts/db/migrations:/docker-entrypoint-initdb.d"
    ports:
      - "5432:5432"
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready" ]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  redis:
  postgres: